\documentclass[twocolumn]{article}


\title{Creating a Textual Entailment Dataset Automatically from Guardian Articles}

\author{Daoud Clarke}

\date{\today}

\usepackage[round]{natbib}

\begin{document}

\maketitle

\section{Introduction}

Recognising textual entailment is the task of determining, given two
sentences, whether the first entails or implies the second. An
entailment dataset is a set of triples $(t,h,e)$ where $t$ is the
\emph{text} or entailing sentence, $h$ is the \emph{hypothesis} or
entailed sentence, and $e$ is a Boolean value indicating whether
entailment holds or not. Datasets are normally constructed by manual
analysis, which is time consuming and thus limits the size of dataset
that can be constructed.

In this document, we will describe a process for constructing a
textual entailment dataset automatically, based on an idea introduced
by \cite{Burger:05} and developed by \cite{Hickl:06}.

\section{Background}



\bibliography{rte}
\bibliographystyle{plainnat}

\end{document}